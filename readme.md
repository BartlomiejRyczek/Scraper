# ğŸ“Œ Automatyczny Web Scraper Ofert Pracy IT

## ğŸ“Œ Opis projektu
Ten projekt zawiera **automatyczny scraper** do pobierania ofert pracy IT z dwÃ³ch popularnych portali:
- **Pracuj.pl**
- **JustJoin.it**

Dane sÄ… przetwarzane, filtrowane i zapisywane do plikÃ³w CSV, aby umoÅ¼liwiÄ‡ pÃ³ÅºniejszÄ… analizÄ™.

---

## ğŸš€ Funkcje projektu
- âœ… **ObsÅ‚uga dynamicznych stron** - Selenium w tle przewija stronÄ™, aby pobraÄ‡ wszystkie dostÄ™pne oferty. 
- âœ… **Automatyczne pobieranie ofert pracy** - skrypty mogÄ… automatycznie uruchamiaÄ‡ siÄ™ przy kaÅ¼dym starcie komputera, gdy plik BAT zostanie umieszczony w folderze autostartu.
- âœ… **Zapis do CSV** - pobrane dane sÄ… przechowywane w pliku `job_offerts.csv` oraz `job_offerts_just_join.csv`.   
- âœ… **Unikanie duplikatÃ³w** - w notebooku eliminuje siÄ™ duplikaty oraz scala dane
- âœ… **Zapis do CSV** - ujednolicone dane sÄ… przechowywane w pliku `oferty_pracy_bez_duplikatow.csv`.  
- âœ… **ObsÅ‚uga wynagrodzeÅ„ i technologii** - ekstrakcja technologii i wideÅ‚ek pÅ‚acowych.  
- âœ… **Analiza danych** - statystyki, wykresy i analiza trendÃ³w.


---

## ğŸ›  Wymagania
ğŸ”¹ **Python 3.x**  
ğŸ”¹ **Selenium**  
ğŸ”¹ **BeautifulSoup**  
ğŸ”¹ **Pandas**  
ğŸ”¹ **Matplotlib** 

Aby zainstalowaÄ‡ wymagane biblioteki, uruchom:
```bash
pip install -r requirements.txt
```

---

## âš™ Instalacja i uruchomienie
### **1ï¸âƒ£ Uruchamianie rÄ™czne skryptÃ³w**
Uruchom scraper dla Pracuj.pl:
```bash
python scraper_pracuj_pl.py
```
Uruchom scraper dla JustJoin.it:
```bash
python scraper_just_join.py
```

### **3ï¸âƒ£ Automatyczne uruchamianie przy starcie systemu**
Uruchom plik `runScrapers.bat`, ktÃ³ry automatycznie uruchomi oba skrypty (pamiÄ™taj o zmienieniu Å›cieÅ¼ki, by byÅ‚a poprawna)
Polecam dodaÄ‡ rÃ³wnieÅ¼ ten plik do autostarty systemu, w celu automatycznego scrapowania danych przy kazdym starcie komputera. 

---

## ğŸ“Š Analiza danych
Dane sÄ… analizowane w pliku **analizaDanych.ipynb**, gdzie moÅ¼na:
- ğŸ† **ZbadaÄ‡ Å›rednie wynagrodzenie w rÃ³Å¼nych technologiach**
- ğŸ“ˆ **WykonaÄ‡ analizÄ™ trendÃ³w iloÅ›ci ofert w czasie**
- ğŸ“Š **ZwizualizowaÄ‡ rozkÅ‚ad wynagrodzeÅ„**
- ğŸ” **SprawdziÄ‡, ktÃ³re technologie sÄ… najczÄ™Å›ciej wymagane**

---

## ğŸš€ Potencjalne ulepszenia projektu
ğŸ”¹ **UÅ¼ycie bazy danych (SQLite/PostgreSQL) zamiast CSV**  
ğŸ”¹ **Lepsza obsÅ‚uga bÅ‚Ä™dÃ³w i logowanie (`logging`)**  
ğŸ”¹ **Scrapowanie asynchroniczne dla lepszej wydajnoÅ›ci (`Asyncio`, `Scrapy`)**  
ğŸ”¹ **Dodanie analizy lokalizacji ofert i generowanie mapy (Folium)**  
ğŸ”¹ **Wizualizacja trendÃ³w w czasie (np. popularnoÅ›Ä‡ jÄ™zykÃ³w programowania)**  
ğŸ”¹ **Integracja z AI (np. analiza treÅ›ci ofert przez GPT)**


# âš ï¸ Uwagi
* W skryptach uÅ¼ywany jest mechanizm porÃ³wnywania rekordÃ³w, by unikaÄ‡ duplikatÃ³w â€“ sprawdza klucze unikalnoÅ›ci (TytuÅ‚, Firma, Link).
* W plikach CSV przechowywane sÄ… m.in. tytuÅ‚ oferty, firma, data, wynagrodzenie, technologie oraz link.
* Plik convert_to_tidy_data.py nie jest potrzebny do prawidÅ‚owego dziaÅ‚ania programu (Jest w trakcie rozwoju)